# 为什么多项式上的点可以确定一个唯一的多项式

我们知道，两点可以确定一条直线。而直线实际上就是一个 一次多项式 $f(x) = kx + b$ .更加一般的, n+1个点，可以确定一个n次多项式，而且这个多项式是唯一的。

下面是证明：

已知：n+1 个点, $(x_0,y_0),(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)$, 这n+1个点，可以确定多个多项式，我们任意点取其中两个: $L_1=k_0+k_1x+k_2x^2+\cdots+k_nx^n$ 和 $L_2=k_0'+k_1'x+k_2'x^2+\cdots+k_n'x^n$

$$
\begin{bmatrix}
    1 & 2 & 3 \\
    4 & 5 & 6 \\
    7 & 8 & 9
\end{bmatrix}
$$

$$
\left[
\begin{matrix}
    1      & 2      & \cdots & 4      \\
    7      & 6      & \cdots & 5      \\
    \vdots & \vdots & \ddots & \vdots \\
    8      & 9      & \cdots & 0      \\
\end{matrix}
\right] \tag{5}
$$

我们把这 n+1 个点带入多项式，然后，可以得到两个矩阵表示的方程组

$$
\begin{bmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^n\\
1 & x_1 & x_1^2 & \cdots & x_1^n\\
\vdots & \vdots & \vdots & & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^n\\
\end{bmatrix}
\begin{bmatrix}
k_0\\
k_1\\
\vdots \\
k_n\\
\end{bmatrix}
$$

=
\begin{bmatrix}
y_0 \\
y_1 \\
\vdots \\
y_n
\end{bmatrix}
$$

$$\begin{bmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^n\\
1 & x_1 & x_1^2 & \cdots & x_1^n\\
\vdots & \vdots & \vdots & & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^n\\
\end{bmatrix}
\begin{bmatrix}
k_0'\\
k_1'\\
\vdots \\
k_n'\\
\end{bmatrix}
=
\begin{bmatrix}
y_0 \\
y_1 \\
\vdots \\
y_n
\end{bmatrix}$$

然后，两个方程组对应相减，那么可以得到如下：
$$\begin{bmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^n\\
1 & x_1 & x_1^2 & \cdots & x_1^n\\\
vdots & \vdots & \vdots & & \vdots \\
1 & x_n & x_n^2 & \cdots & x_n^n\\
\end{bmatrix}
\begin{bmatrix}
k_0-k_0'\\
k_1-k_1'\\
\vdots \\
k_n-k_n'\\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
\vdots \\0
\end{bmatrix}
$$

我们知道，n元齐次线性方程组有非零解的充要条件是其系数行列式为零。所以，我们需要计算行列式。我们知道, $det(A^T) = det(A)$, 我们把矩阵转置之后，这个行列式就是范德蒙德行列式。这个行列式的计算公式如下：

$$
\begin{vmatrix}
1&1&1&\cdots&1 \\
x_0&x_1&x_2&\cdots&x_n \\
x_0^2&x_1^2&x_2^2&\cdots&x_n^2 \\
\vdots & \vdots & \vdots & & \vdots \\
x_0^n&x_1^n&x_2^n&\cdots&x_n^n \\
\end{vmatrix}
=
\prod_{n\ge i > j \ge 0 }(x_i-x_j)
$$

很明显，因为上面的点都是不同的点, $\forall i\ne j, x_i \ne x_j$ 这样，这个行列式不可能为零。那么只有
$$
k_i - k_i' = 0\\
k_i = k_i' \\
L_1 = L_2
$$

也就是n+1个点可以唯一确定一个n次多项式。
